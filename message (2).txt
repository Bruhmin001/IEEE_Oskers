import streamlit as st
import pandas as pd
import pickle
import os
import numpy as np

def load_pkl(filename):
    if os.path.exists(filename):
        with open(filename, 'rb') as f:
            return pickle.load(f)
    return None

def calculate_seasonal_average(df, district):
    # Debug print to check district values
    st.write(f"Debug: Looking for district '{district}'")
    st.write(f"Debug: Available districts: {df['Dist Name'].unique()}")
    
    # Filter data for selected district
    df_district = df[df['Dist Name'] == district]
    
    # Debug check: Is data available for this district?
    if df_district.empty:
        st.error(f"No data found for district: {district}")
        st.write(f"Debug: District dataframe is empty")
        return pd.DataFrame()
    else:
        st.write(f"Debug: Found {len(df_district)} rows for district {district}")
    
    # Debug: Show columns in the dataframe
    st.write(f"Debug: Available columns: {df_district.columns.tolist()}")
    
    required_columns = {
        'Summer': ['MARCH MAXIMUM (Centigrate)', 'APRIL MAXIMUM (Centigrate)', 'MAY MAXIMUM (Centigrate)'],
        'Monsoon': ['JUNE MAXIMUM (Centigrate)', 'JULY MAXIMUM (Centigrate)', 'AUGUST MAXIMUM (Centigrate)', 'SEPTEMBER MAXIMUM (Centigrate)'],
        'Winter': ['OCTOBER MAXIMUM (Centigrate)', 'NOVEMBER MAXIMUM (Centigrate)', 'DECEMBER MAXIMUM (Centigrate)', 'JANUARY MAXIMUM (Centigrate)', 'FEBRUARY MAXIMUM (Centigrate)']
    }
    
    # Create a new DataFrame for seasonal data
    seasonal_data = {}
    
    # Debug: Check each season calculation
    for season, cols in required_columns.items():
        available_cols = [col for col in cols if col in df_district.columns]
        
        st.write(f"Debug: For {season}, found {len(available_cols)}/{len(cols)} columns")
        if available_cols:
            st.write(f"Debug: Available columns for {season}: {available_cols}")
            
            # Check for NaN values
            has_nan = df_district[available_cols].isna().any().any()
            st.write(f"Debug: NaN values present in {season} data: {has_nan}")
            
            # Calculate season average row-wise (for each year/record)
            seasonal_data[season] = df_district[available_cols].mean(axis=1).values
        else:
            st.write(f"Debug: No columns available for {season}")
            seasonal_data[season] = np.nan
    
    # Convert dictionary to DataFrame
    result = pd.DataFrame(seasonal_data, index=df_district.index)
    
    # Debug: Final seasonal data shape and values
    st.write(f"Debug: Seasonal data shape: {result.shape}")
    st.write(f"Debug: Seasonal data sample: {result.head(2).to_dict()}")
    
    return result

def main():
    st.title("District-wise Crop Yield Prediction")
    
    # Load dataset
    file_path = 'combined_data.csv'
    if not os.path.exists(file_path):
        st.error("Dataset not found!")
        return
    
    try:
        df = pd.read_csv(file_path)
        st.write("### Step 1: Dataset Loaded")
        
        # Debug: Show dataset info
        st.write(f"Debug: Dataset shape: {df.shape}")
        st.write(f"Debug: Columns with NaN values: {df.columns[df.isna().any()].tolist()}")
        
        st.dataframe(df.head())
    except Exception as e:
        st.error(f"Error loading dataset: {e}")
        return
    
    # Check if 'Dist Name' column exists
    if 'Dist Name' not in df.columns:
        st.error("Error: No 'Dist Name' column found in dataset!")
        
        # Debug: Show available columns
        st.write(f"Debug: Available columns: {df.columns.tolist()}")
        return
    
    # Select district
    districts = sorted(df['Dist Name'].unique())
    selected_district = st.selectbox("Select a district:", districts)
    
    if selected_district:
        st.write(f"### Step 2: Selected District - {selected_district}")
        
        # Load prediction model specific to district
        model_filename = f"{selected_district}_sarimax_model.pkl"
        st.write(f"Debug: Looking for model file: {model_filename}")
        
        model = load_pkl(model_filename)
        if model is not None:
            st.write("### Step 3: Model Loaded")
            
            # Calculate seasonal averages
            try:
                seasonal_avg = calculate_seasonal_average(df, selected_district)
                
                if seasonal_avg.empty:
                    st.error("No seasonal data available for the selected district!")
                    return
                
                st.write("### Step 4: Seasonal Averages")
                st.dataframe(seasonal_avg.tail(5))
                
                # Add sliders for simulation
                st.write("### Step 5: Adjust Seasonal Variables for Simulation")
                
                adjusted_seasonal_data = {}
                for col in seasonal_avg.columns:
                    # Handle potential NaN values when calculating min/max/mean
                    col_data = seasonal_avg[col].dropna()
                    
                    if len(col_data) > 0:
                        col_min = float(col_data.min())
                        col_max = float(col_data.max())
                        col_mean = float(col_data.mean())
                        
                        # Debug slider values
                        st.write(f"Debug: {col} slider range: {col_min} to {col_max}, default: {col_mean}")
                        
                        adjusted_value = st.slider(
                            f"{col}", 
                            min_value=col_min,
                            max_value=col_max,
                            value=col_mean
                        )
                        adjusted_seasonal_data[col] = adjusted_value
                    else:
                        st.warning(f"No valid data for {col}, using default value")
                        adjusted_seasonal_data[col] = 0.0
                
                # Create exogenous data for forecast
                exog_data = pd.DataFrame([adjusted_seasonal_data] * 5)  # Create 5 rows with the same values
                
                st.write("Debug: Exogenous data for prediction:")
                st.dataframe(exog_data)
                
                # Make prediction
                try:
                    # Check if model requires exogenous data
                    if hasattr(model, 'exog_names') and model.exog_names is not None:
                        st.write(f"Debug: Model requires exogenous variables: {model.exog_names}")
                        
                        # Ensure exog_data has the correct column names
                        if set(exog_data.columns) != set(model.exog_names):
                            st.error(f"Exogenous variable mismatch! Model expects: {model.exog_names}")
                            return
                    
                    predictions = model.forecast(steps=5, exog=exog_data)
                    st.write("### Step 6: Predictions")
                    st.dataframe(pd.DataFrame(predictions, columns=['Predicted Yield']))
                except Exception as e:
                    st.error(f"Prediction error: {e}")
                    st.write(f"Debug: Exception details: {type(e).__name__}")
                    import traceback
                    st.write(f"Debug: {traceback.format_exc()}")
            
            except Exception as e:
                st.error(f"Error calculating seasonal averages: {e}")
                import traceback
                st.write(f"Debug: {traceback.format_exc()}")
        else:
            st.error(f"Prediction model not found for {selected_district}!")
            st.write(f"Debug: Check if '{model_filename}' exists in the current directory")

if __name__ == "__main__":
    main()